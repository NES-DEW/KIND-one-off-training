{
  "hash": "7371629fee5c09c98b22532060d668a8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"An introduction to AI (...and why you might avoid that term)\"\ndate: 2024-07-01\nbibliography: \"src/references.bib\"\nexecute: \n  freeze: auto\n---\n\n  \n## Previous attendees have said...  \n- 18 previous attendees have left feedback\n- 100% said that this session was pitched correctly\n- 100% would recommend this session to a colleague\n  \n:::{.callout-note}  \n### Three random comments from previous attendees  \n- Very nice introduction and exciting start for staff to familiarise ourselves with AI concepts.\n- As a clinician who is interested in data, AI and so on, I learned a lot and enjoyed the whole session.\n- The side discussions are always an exciting and valuable part of the informal training sessions - even the ones which are only tenuously linked. The content could have been offered as a slide deck ... but it is the side discussions which add substantial value (and interest) beyond anything which could simply be trawled from the internet\n  \n:::  \n\n\n:::{.callout-note collapse=false appearance='default' icon=true}\n## Session materials\n+ [all materials {{< iconify ph:file-zip size=2x >}}](src/ai_intro.zip)\n+ slides [{{< iconify ph:file-html size=2x >}} html](src/ai_intro.html) / [{{< iconify ph:file-pdf size=2x >}} pdf](src/ai_intro.pdf)\n:::\n\n## Welcome\n* this session is üå∂: for beginners\n\n## Motive\n\n-   There's a *lot* of hype about AI at the moment (see [this graph](https://www.google.com/imgres?imgurl=https%3A%2F%2Fassets.bwbx.io%2Fimages%2Fusers%2FiqjWHBFdfxIU%2Fi8RUqd2T_1Bs%2Fv2%2FpidjEfPlU1QWZop3vfGKsrX.ke8XuWirGYh1PKgEw44kE%2F-1x-1.png&tbnid=TPmvfqSuBPNC2M&vet=12ahUKEwjw5fuQs4WHAxUkU6QEHZyfDdkQMygDegQIARBP..i&imgrefurl=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2024-06-06%2Fnvidia-microsoft-and-apple-are-bigger-than-china-s-stock-market&docid=beNq4RhizA7SbM&w=1200&h=675&q=nvidia%20microsoft%20graph&ved=2ahUKEwjw5fuQs4WHAxUkU6QEHZyfDdkQMygDegQIARBP))\n-   Underneath the hype, there's a lot of genuinely exciting stuff going on too\n-   That exciting stuff is likely to have some impact on health and care work\n-   But the timing and nature of that impact is unclear\n\n# Three questions for you\n\n## What does AI mean to you?\n\n::: {layout-nrow=2}\n\n![HAL](src/images/hal.jpg){width=\"300\" height=\"300\"}\n\n![Terminator](src/images/arnie.jpg){width=\"300\" height=\"300\"}\n\n![Pope in puffa jacket](src/images/pope.jpg){width=\"300\" height=\"300\"}\n\n![Siri](src/images/siri.jpg){width=\"300\" height=\"300\"}\n:::\n\n## Is AI...\n+ Over-hyped?\n+ Somewhere in between?\n+ Neglected?\n+ Other / don't know\n\n## Do submarines swim?\n\n## About this talk\n\n- AI is hard\n  - lots of different technologies\n  - lots of new words\n  - lots of promises and implications\n-   So let's start with a thought experiment\n\n## The Chinese room\n\n@searle1980\n\n> \"Suppose that I'm locked in a room and given a large batch of Chinese writing. Suppose furthermore (as is indeed the case) that I know no Chinese, either written or spoken, and that I'm not even confident that I could recognize Chinese writing\"\n\nHowever, he is supplied with a set of intelligible rules for manipulating these Chinese symbols\n\n> \"ÁÅ´\" is the opposite of \"Ê∞¥\"\n> \"ÂÖ≠\" is more than \"Âõõ\"\n\n## Question\n\nDoes this poor bloke locked in a room understand the Chinese symbols?\n\nNow suppose that we start asking him questions (in English):\n\n> Is \"ÂÖ≠\" more than \"Âõõ\"?\n> If so, respond with \"ÊòØ\". Otherwise respond \"‰∏ç\"\n\n\n## Question\n\n-   Is understanding the same thing as being able to produce output in response to input?\n\n- @searle1980 - this is the difference between strong and weak AI\n\n\n## Back to nice safe words\n\n-   we usually don't worry too much about what words like intelligence, understanding, etc really mean\n-   for most purposes, understanding something, and doing that thing, pretty well overlap\n-   AI, unfortunately, is an exception\n-   big difference between producing output and understanding here\n\n## Why does this matter?\n\n-   Because the current conversation around AI does violence to our usual understanding of basic terms (like intelligence)\n    -   We need to do a bit of re-interpreting...\n    -   ...particularly because AI can do the input-output part *really* well\n-   (side effect) The Chinese Room is an excellent way of understanding what's going on inside some of the current tech\n\n## What are we talking about\n\n-   AI = big umbrella term, problematic\n    -   understanding?\n-   Let's stick to some narrower concepts\n    -   *Algorithms* = rule-based ways of producing sensible output\n    -   *Expert systems* = more sophisticated expertise-based production of output\n    -   *Machine learning* = umbrella term for non-expertise-based production of output\n    -   *Large Language Models* = sub-species of machine learning\n\n## So what's an algorithm?\n\n::: columns\n::: {.column width=\"25%\"}\n![](src/images/altair.jpg) [(Packard 1979)](https://www.goodreads.com/book/show/191062.The_Third_Planet_from_Altair)\n:::\n\n::: {.column width=\"60%\"}\n-   Algorithm = rule (roughly)\n    -   if something happens, do something\n-   made from expert input and evidence\n:::\n:::\n\n## An example algorithm\n\n![](src/images/nice_136.png){fig-align=\"center\"}\n\n## Related expertise-based tools\n\n\"See also...\" references in indexes, library catalogues, wikipedia\n\n![Cue sports item from Wikipedia with manually-created see also items](src/images/cue.png)\n\n-   [Brilliant 1996 Master's dissertation](https://files.eric.ed.gov/fulltext/ED401916.pdf) looking at the state of \"see also...\" referencing in Ohio's public libraries\n\n## How about something more complicated?\n\n\n::: columns\n:::: {.column width=\"35%\"}\n\n![Monitor rules from MYCIN](src/images/monitor.png)\n::::\n\n:::: {.column width=\"60%\"}\n- one problem with algorithms: how to handle conflicting information?\n-   An expert system - [MYCIN](https://en.wikipedia.org/wiki/Mycin) [@shortliffe1975]\n    -   designed to identify bacterial infections and suitable Rx\n    -   600 rules, supplied by experts\n    -   asks users a series of clinical questions\n    -   combines the answers using a (fairly simple) inference system\n    -   able to manage some conflicting information - unlike simpler algorithms\n\n::::\n\n:::\n\n## Machine learning\n\n-   A next step: can we provide learning rules to a system, and let it figure out the details for itself?\n\n![https://commons.wikimedia.org/wiki/File:Supervised_machine_learning_in_a_nutshell.svg](src/images/sml.png)\n\n## This is supervised learning\n\n-   supervision = labelled observations used for training and testing\n-   Lots of health examples with promising results:\n    -   diabetic retinopathy [@mookiah2013]\n    -   ECG [@aziz2021]\n    -   fractures, melanoma, ...\n\n## A dataset downside\n\n::: columns\n::: {.column width=\"40%\"}\n![[Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)](src/images/mnist.png)\n:::\n\n::: {.column width=\"50%\"}\nProducing labelled datasets is hard:\n\n-   generally must be very large\n-   generally requires expert classification\n-   must be done with great accuracy\n    -   scale bar problem [@winkler2021]\n-   so dataset labelling is wildly expensive and thankless\n    -   Is there a way of doing something similar without spending millions classifying everything in the world by hand?\n:::\n:::\n\n## Unsupervised learning\n\n![English-language Google search results for large](src/images/google.png){height=\"300\"}\n\n## Unsupervised learning\n\n![Google's summary of where autocomplete predictions come from](src/images/explain.png){height=\"300\"}\n\n## Unsupervised learning\n\n![German-language Google search results for gross](src/images/go√∂gle.png){height=\"300\"}\n\n## Unsupervised learning\n\n-   No-one is writing a list of possible searches starting with \"Large...\"\n-   Nor are they classifying searches into likely/unlikely, then training a model\n-   Instead, the model is looking at data (searches, language, location, trends) and calculating probabilities\n    -   [2011 blog post](https://googleblog.blogspot.com/2011/04/more-predictions-in-autocomplete.html)\n    -   [2020 PR piece](https://blog.google/products/search/how-google-autocomplete-predictions-work/)\n    -   [2020 build your own in JS](https://medium.com/analytics-vidhya/build-a-simple-autocomplete-model-with-your-own-google-search-history-ead26b3b6bd4)\n-   The terminology gets confusing again at this point:\n    -   some describe this as *deep learning*\n    -   better to call this a *language model*\n\n## Large language models\n\nWhat if we were more ambitious with the scope of our language model?\n\n::: columns\n::: {.column width=\"30%\"}\n![Transformer structure](src/images/transformer.png)\n:::\n\n::: {.column width=\"60%\"}\n-   Find masses of language data\n    -   chatGPT uses basically the whole web before September 2021\n-   Build a model capable of finding patterns in that data\n    -   Attention model used in chatGPT [@vaswani2017]\n-   Allow the model to calculate probabilities based on those patterns\n    -   lots of work going on at present allowing models to improve in response to feedback etc\n:::\n:::\n\n## Large language models\n\n-   superb at generating appropriate text, code, images, music...\n-   but production vs understanding\n    -   e.g. hallucinations, phantom functions...\n-   training is extremely computationally expensive\n    -   questions about inequality and regulatory moating\n        -   no-one but FAANG-sized companies can afford to do this\n    - training is also surprisingly manual\n\n## Ethics\n\n- your web content, my model, my paycheque\n- where's the consent here?\n- big serious worries about bias in some kinds of output\n- rights violations via AI\n- no settled questions around responsibility\n- UK GDPR etc assume data is identifiable. That's not true in LLMs.\n\n## Punchline\n\n-   On balance, while there's hype here, there's also lots of substance and interest\n-   LLMs have become *much* better at producing plausible output, across a *greatly* expanded area\n-   A strength: fantastic ways for those with expertise to work faster\n-   A danger: LLMs are great at producing truth-like output. Good enough so that some will be tempted to use them to extend their apparent expertise...\n-   But big serious legal and ethical trouble ahead - we're not good at dealing with distributed responsibility\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}