---
title: Data masking in R
date: 2024-09-23
execute: 
  echo: true
  eval: true
  output: true
  freeze: auto
categories: [R, intermediate, functions, debugging]
editor_options: 
  chunk_output_type: console
---

::: {.callout-note collapse="false" appearance="default" icon="true"}
## Session materials

[Data masking cheatsheet {{< iconify ph:file-pdf size=2x >}}](src/te_cheat_sheet.pdf)

:::


```{r}
library(NHSRdatasets)
library(dplyr)
library(purrr)
library(ggplot2)
```


## Introduction

More so than in other programming languages, R functions bias towards helping the user do common tasks easily. One excellent example is the way that tidyverse functions (like dplyr) make assumptions about what users mean when they refer to variables. As an example:

```{r}
stranded_data |> 
  select(age) 
```

When we specify the age column in this select function, we don't need to tell R that we specifically mean the age column in the `stranded_data` tibble. That's very helpful, because it saves us having to specify that we want to refer to a specific column in a specific tibble each time we write a line of dplyr. Even if we create another tibble that also has an age column...

```{r}
new_stranded_data <- stranded_data |>
  select(stranded.label, age)
```

... we can still just refer to the age column of the original `stranded_data` without any risk of confusion. This simplification - which we'll call **data masking** - is a great advantage of using the pipe, and most of the time data masking just works without giving rise to any problems at all. For example, we can write a vector of column names, and then pass it to `select()`, and R will figure out that we want to use those names as column names without any extra effort on our part:

```{r}
my_cols <- c("age", "care.home.referral", "medicallysafe")

stranded_data |>
  select(any_of(my_cols))

```

That means that cases where data masking goes wrong can be enormously frustrating, because most of the time we don't have to think about what are code is *really* doing very often at all. Here's an example of such a problem in a function that picks a specified column from `stranded_data` and displays it:

```{r}
column_displayer <- function(col_name) {
  stranded_data |>
  select(any_of(col_name)) 
}
```

If we try to use this `column_displayer()` function in the normal way, we'll receive an error:

```{r results='markup'}
try(column_displayer(age))
```

Okay, so we can dodge this error in this case by quoting the column name when we supply it as an argument:

```{r}
column_displayer("age")
```

But this non-standard ["kludge"](https://en.wiktionary.org/wiki/kludge#English) leads to trouble when we want to, for instance, use `column_displayer()` inside another function. A stronger approach is to adjust our function code in the first place, so that we don't have to call our function in a non-standard way (why write *age* in some functions, but *"age"* in others to refer to the same thing).

In this section, we'll give a bit of helpful theoretical background about data masking. We'll then go on to look at four ways of resolving some of the difficulties that data masking can cause.

## Background

The [rlang page on data-masking](https://rlang.r-lib.org/reference/topic-data-mask.html) is very helpful here in setting out a key distinction between kinds of variables that we've previously been using synonymously:

+ env-variables (things you create with assignment)
+ data-variables (e.g. imported data in a tibble)

For beginners, this distinction is not that important, particularly because tidyverse functions do lots of helpful blurring between these different types of variable. Note that many base R functions do often require the user to bear this distinction in mind. For instance, in base R you would specify a data variable differently from an environment variable:

```{r eval=F}
mtcars$cyl      # a data variable
cyl <- c(4,6,8) # an environment variable
```

Whereas in tidyverse, you can:

```{r eval=F}
mtcars |>
  select(cyl) # specifying a data variable like an environment variable inside select
```

Most of the time, data masking doesn't cause any problems. However, when you start wanting to include tidyverse functions inside other functions, that blurring raises a problem. We won't give much of an explanation as to the reasons for this, although do read [this introduction to the topic](https://rlang.r-lib.org/reference/topic-data-mask.html) and [this more detailed account](https://rlang.r-lib.org/reference/topic-data-mask-ambiguity.html) if you are interested in the technical aspects. Here, we'll concentrate on four strategies for resolving these kind of data masking problems. These strategies are:

```{r echo=F}
tribble(
  ~Problem, ~Solution,
  "data-variable in a function argument", "**embracing** with `{{var}}`",
  "env-variable in a vector", "`.data[[var]]` and `.env[[var]]` **pronouns**", 
  "variables in output", "**injection** with **`:=`**",
  "complex cases", "**quasiquotation** with the injection operator `!!`"
) 

```


## Embracing

Slightly confusingly, this practice is also referred to [as *tunneling* data] variables(https://www.tidyverse.org/blog/2020/02/glue-strings-and-tidy-eval/)

If you want to use a data variable in the argument of a function, you need to ``{{embrace}}`` the argument. Here's some code to produce a rounded mean of a column in `ae_attendances` in cases where breaches are over 100:

```{r results='markup'}
ae_attendances |>
  filter(breaches > 100) |>
  pull(attendances) |>
  mean() |>
  round(2)
```

We can generalise this to a function, which won't work properly:

```{r results='markup'}
ae_means <- function(colname) {
  ae_attendances |>
    filter(breaches > 100) |>
    pull(colname) |>
    mean() |>
    round(2)
}

try(ae_means(breaches))
```

However, if we embrace the argument in the `pull()` call:

```{r results='markup'}
ae_means <- function(colname) {
  ae_attendances |>
    filter(breaches > 100) |>
    pull({{colname}}) |>
    mean() |>
    round(2)
}
```

We can use that new function in a standard way:

```{r results='markup'}
ae_means(breaches)
ae_means(admissions)
```

And that's worthwhile, because (unlike the non-standard quoted version earlier) we can then use that functions e.g. with `purrr`:

```{r}
orgs <- ae_attendances |> 
        select(where(is.numeric)) |> 
        names()

purrr::map(orgs, ae_means)
```



## Pronouns

If you want to use an variable that comes from a character vector, then use **pronouns**. Pronouns allow you to specify how a variable should be interpreted. If we create an atomic vector:

```{r}
variable <- c("type")
```

We might then try to use this variable inside `count()`, but there are horrors there:
```{r results='markup'}
try(ae_attendances |>
  count(variable))
```

If we now add the `.data[[]]` pronoun:

```{r}
ae_attendances |>
  count(.data[[variable]]) 
```

The `.env[[]]` pronoun works in a similar way. Imagine that we happen to have an env-variable that shares the name of one of our data-variables:

```{r}
attendances <- 800
```

If we try to use it to filter our data, we'll run into a problem:

```{r}
ae_attendances |>
  filter(breaches >= attendances) 
```

(this is based on an actual problem I manufactured for myself while writing the functions training)

This gives an unexpected result, because there are *definitely* cases where we have more than 800 breaches. In fact we have something like `r nrow(ae_attendances |> filter(breaches >= 800))` cases with more than 800 breaches. And what's going on here is that there's an ambiguity - which `attendances` do we mean? This is where pronouns come in, by allowing us to be precise about where the variable is coming from:

```{r}
ae_attendances |>
  filter(.data[["breaches"]] >= .env[["attendances"]]) |> 
  arrange(breaches) 
```
(you can get away, in this case, without the `.data[[]]`, but included here as an extra example)


## Injection

**`:=`** lets you inject variables into your output. For example, to ensure that the name of a new summary column matches a supplied column name in a function, we can inject the variable into the newly-created column name:

```{r}
col_means <- function(column, cutoff) {

ae_attendances |>
  filter({{column}} > {{cutoff}}) |>
  group_by(type) |>
  summarise("mean_{column}" := round(mean(.data[[column]]), 1)) 
}

```

The column name is created using `glue()` syntax. `glue()` is a neat replacement for base-R tools like `paste0()`:

```{r}
column <- c("breaches")
cutoff <- 400

cat(glue::glue("This is how we'd include the column ({column}), and the cutoff ({cutoff}) in Quarto/Rmarkdown using `glue`")) # easier to read

```

The column name is then injected using the `:=` operator. When we call our `col_means()` function, the supplied column name is injected into the new summary column:

```{r}
col_means("attendances", 400)
```

Similar injections can be applied across a range of dplyr functions. We'll demonstrate these below using a vector containing the new column name, but injection is most useful when included as part of a function that you might want to apply across several different aspects of your data:

```{r}

new_column_name <- c("Steve")

ae_attendances |> 
  mutate("{new_column_name}" := round(attendances ^ 0.5, 2) )

ae_attendances |> 
  rename("{new_column_name}" := attendances) 

ae_attendances |> 
  group_by(org_code) |>
  summarise("{new_column_name}" := n()) |>
  arrange(.data[[new_column_name]]) |>
  slice(1:10) |>
  ggplot() +
  geom_col(aes(x=org_code, y=.data[[new_column_name]])) +
  ggtitle(glue::glue("{new_column_name} by org_code"))
  
```

## Quasiquotation

Informally, the `:=` operator that we explored in the previous subsection functions behaved *as if* it were adding quotes around the variable that was passed to it. That meant that we could pass a quoted variable to a function, and yet return the result as expected:

```{r}
quoted_variable <- "Steve"

ae_attendances |> 
  rename("{quoted_variable}" := attendances) 
```

What if we also need to use this variable in an unquoted way? For example, say we now want to use `select()` to pick out our `r quoted_variable` column? 

In a function where an argument is supplied quoted, you can unquote it with `!!`:

```{r}
ae_attendances |> 
  rename("{quoted_variable}" := attendances) |>
  select(!!quoted_variable) 
```

That gives us a useful and clear way of thinking about quasiquotation. To borrow the description from the manual page:

> Quasiquotation is the combination of quoting an expression while allowing immediate evaluation (unquoting) of part of that expression. ([rlang quasiquotation manual page](https://www.rdocumentation.org/packages/rlang/versions/0.2.1/topics/quasiquotation))

And the strength of using quasiquotation is that it grants lots of scope for handling variables in comparatively complicated function. For example, if we want to create a function to take a supplied tibble and column name, and generate a bit of Rmarkdown with a header and summary of that column, quasiquotation (and injection) allow us to wrangle our variables so that they are compatible with the tidyverse functions that we'd like to use:

```{r}
distinct_entries <- function(df, col_name){
  
  cat(glue::glue("#### Results for {col_name}:  \n  \n")) # using glue syntax
  
  df |> 
    select(!!sym(col_name)) |> # using quasiquotation to select the supplied column
    rename("distinct_{col_name}" := col_name) |> # using injection to rename the column
    distinct() 
}

distinct_entries(ae_attendances, "org_code")
```
